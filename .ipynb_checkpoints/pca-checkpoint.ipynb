{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbYU_-phmlwH"
   },
   "source": [
    "Principal Component Analysis\n",
    "PCA is a technique used for dimensionality reduction and feature extraction by transforming the original dataset into a new set of linearly uncorrelated variables called principal components. The first principal component has the highest variance and each subsequent component has the highest variance under the constraint of being orthogonal to the previous components.\n",
    "The number of principal components to keep is usually determined by the amount of variance explained by each component. In this case, n_components=2 is specified, which means the data is transformed into a new two-dimensional space spanned by the first two principal components.\n",
    "The transformed data is visualized using a scatter plot, where the x-axis corresponds to the first principal component and the y-axis corresponds to the second principal component. The plot shows how the data is distributed in the new two-dimensional space.\n",
    "Preprocessing\n",
    "This code loads the dataset from the df DataFrame and preprocesses the data for the principal component analysis (PCA).\n",
    "It drops the 'datetime', 'srcstr', 'localeabbr', 'time', 'hour', and 'postalcode' columns from the dataset as they are not useful for the analysis.\n",
    "It also encodes the categorical variables using LabelEncoder() from the sklearn.preprocessing module.\n",
    "The resulting dataset containing only the features is stored in the X DataFrame.\n",
    "Finally, it drops the rows containing null values using the dropna() method and returns the first few rows of the processed dataset using the head() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wGI2cFrnmJaX"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11956\\836908637.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Load the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "d = df\n",
    "d = d.drop('datetime', axis=1)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "d.host = le.fit_transform(d.host)\n",
    "d.proto = le.fit_transform(d.proto)\n",
    "d.cc = le.fit_transform(d.cc)\n",
    "d.country = le.fit_transform(d.country)\n",
    "d.locale = le.fit_transform(d.locale)\n",
    "d.month = le.fit_transform(d.month)\n",
    "\n",
    "# Separate the features from the target variable\n",
    "d = d.drop('srcstr', axis=1)\n",
    "d = d.drop('localeabbr', axis=1)\n",
    "d = d.drop('time', axis=1)\n",
    "d = d.drop('hour', axis=1)\n",
    "d = d.drop('postalcode', axis=1)\n",
    "X = d\n",
    "X=X.dropna()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qXhL3VimyNd"
   },
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qslcf3W4m0OB"
   },
   "outputs": [],
   "source": [
    "# Standardize the feature values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Visualize the transformed data\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1])\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kW9kBChMm2mz"
   },
   "outputs": [],
   "source": [
    "t = df\n",
    "t = t.drop('datetime', axis=1)\n",
    "t = t.drop('srcstr', axis=1)\n",
    "t = t.drop('localeabbr', axis=1)\n",
    "t = t.drop('time', axis=1)\n",
    "t = t.drop('hour', axis=1)\n",
    "t = t.drop('postalcode', axis=1)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "t.host = le.fit_transform(t.host)\n",
    "t.proto = le.fit_transform(t.proto)\n",
    "t.cc = le.fit_transform(t.cc)\n",
    "t.locale = le.fit_transform(t.locale)\n",
    "t.month = le.fit_transform(t.month)\n",
    "t = t.dropna()\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VczIyGWm8X5"
   },
   "source": [
    "This code first imports the required libraries for performing PCA visualization and 3D plot visualization.\n",
    "Then, it selects the columns spt, dpt, latitude, and longitude for PCA visualization from the dataframe t.\n",
    "The selected columns are standardized using StandardScaler(), and PCA is performed on them with 2 components using PCA(n_components=2).\n",
    "Another PCA is performed with 3 components using PCA(n_components=3) for 3D plot visualization.\n",
    "The unique values of the country column are identified and a color map is created using the plt.cm.get_cmap() function.\n",
    "The transformed data is then plotted using scatter plot with each data point colored based on its corresponding country value.\n",
    "Finally, the plot labels, title, legends, and colorbar are set using the set_xlabel(), set_ylabel(), set_title(), legend(), and colorbar() functions of the matplotlib.pyplot library.\n",
    "The resulting plot is displayed using the plt.show() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSAZ4j5om91r"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Select the columns for PCA visualization\n",
    "columns = ['host','spt', 'dpt', 'latitude', 'longitude']\n",
    "\n",
    "# Separate the features from the target variable\n",
    "A = t[columns]\n",
    "A=A.dropna()\n",
    "# Standardize the feature values\n",
    "scaler = StandardScaler()\n",
    "A_scaled = scaler.fit_transform(A)\n",
    "\n",
    "# Perform PCA with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "A_pca_2d = pca.fit_transform(A_scaled)\n",
    "\n",
    "# Perform PCA with 3 components\n",
    "pca = PCA(n_components=3)\n",
    "A_pca_3d = pca.fit_transform(A_scaled)\n",
    "\n",
    "# Create a color map for country column values\n",
    "country_values = t['country'].unique()\n",
    "color_map = plt.cm.get_cmap('hsv', len(country_values))\n",
    "\n",
    "# Visualize the transformed data with color-coded data points in 2D\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "for i, country in enumerate(country_values):\n",
    "    mask = t['country'] == country\n",
    "    ax.scatter(A_pca_2d[mask, 0], A_pca_2d[mask, 1], c=color_map(i), marker='o', label=country)\n",
    "\n",
    "# Set the plot labels and title\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_title('AWS Honeypot Dataset - PCA Visualization (2D)')\n",
    "\n",
    "# Add legends and colorbar\n",
    "ax.legend(bbox_to_anchor=(1.95, 1.50), fontsize=\"8\")\n",
    "sm = plt.cm.ScalarMappable(cmap=color_map, norm=plt.Normalize(vmin=0, vmax=len(country_values)-1))\n",
    "sm.set_array([])\n",
    "fig.colorbar(sm)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OD3YebHWnJvc"
   },
   "source": [
    "This code reads in the dataset dx, normalizes the values in each column (except for certain columns), drops any rows with missing values, and then checks for the presence of missing values in the resulting dataset.\n",
    "\n",
    "The normalization is done by dividing each value in a column by the maximum value in that column. This scales all the values in each column to lie between 0 and 1.\n",
    "\n",
    "The specific columns excluded from normalization are 'datetime', 'host', 'src', 'proto', and 'type'. This suggests that these columns may not contain numerical data that is amenable to normalization.\n",
    "\n",
    "The code then drops any rows in dx that contain missing values, and finally uses the isnull() and sum() methods to count the number of missing values in the resulting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0soutHTnK0T"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "# Read the dataset\n",
    "\n",
    "dx= d\n",
    "\n",
    "# Normalize the data\n",
    "for col in dx.columns:\n",
    "    if col != 'datetime' and col != 'host' and col != 'src' and col != 'proto' and col != 'type':\n",
    "        dx[col] = dx[col].astype('float')\n",
    "        dx[col] = dx[col] / dx[col].max()\n",
    "\n",
    "dx = dx.dropna()\n",
    "dx.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3xf8k0knNW_"
   },
   "outputs": [],
   "source": [
    "dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTYwdDMhnTcD"
   },
   "source": [
    "This code is performing PCA (Principal Component Analysis) on the normalized dataset dx and visualizing the PCA dimensions in 3D and 2D.\n",
    "\n",
    "First, the code creates a 3D plot using the scatter function of matplotlib and the projection='3d' parameter. It then plots the transformed dataset pca_transformed on the x, y, and z axes, with the color of each point determined by the corresponding country value in the dx DataFrame.\n",
    "\n",
    "Next, the code creates a 2D scatter plot using the sns.scatterplot function from the seaborn library. It plots the first two principal components (PCA1 and PCA2) on the x and y axes, respectively, with the color of each point determined by the corresponding country value in the dx DataFrame.\n",
    "\n",
    "Finally, both the 3D and 2D plots are displayed using the plt.show() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVmBm8gOnULP"
   },
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca_transformed = pca.fit_transform(dx.drop(['host', 'src', 'proto'], axis=1))\n",
    "\n",
    "# Visualize PCA dimensions\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pca_transformed[:,0], pca_transformed[:,1], pca_transformed[:,2], c=dx['country'], cmap='viridis')\n",
    "ax.set_xlabel('PCA1')\n",
    "ax.set_ylabel('PCA2')\n",
    "ax.set_zlabel('PCA3')\n",
    "plt.show()\n",
    "\n",
    "# 2D Visualization\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.scatterplot(x=pca_transformed[:,0], y=pca_transformed[:,1], hue=dx['country'], palette='hls')\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
